{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b7922d-0ecb-4c03-b870-244803b76158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3286240-ccb9-465b-8b07-d8f3db5a00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"../data/parsed_files\" / Path(name) for name in os.listdir(\"../data/parsed_files\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38994c9-cbd5-440f-a227-e31f9e33b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f60608e-c32c-472a-83f1-097892af9110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 148}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chroma is used in-memory so we use the same instances in the two pipelines below\n",
    "document_store = ChromaDocumentStore()\n",
    "\n",
    "indexing = Pipeline()\n",
    "indexing.add_component(\"converter\", TextFileToDocument())\n",
    "indexing.add_component(\"writer\", DocumentWriter(document_store))\n",
    "indexing.connect(\"converter\", \"writer\")\n",
    "indexing.run({\"converter\": {\"sources\": file_paths}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a18c20-94bb-4a08-b31e-b66da77d0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "# from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab14a313-8357-4eb3-abda-cab4a55cddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"hf.co/IlyaGusev/saiga_nemo_12b_gguf:Q8_0\"\n",
    "MODEL_NAME = \"qwen2.5:7b\"\n",
    "llm = OpenAIGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96cf2da7-aaa0-464f-9cb5-31e36b2769fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = llm.run(\"What is the most interesting thing you know?\")\n",
    "for answer in result[\"replies\"]:\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84719e5-08cd-425b-b7be-60f0289489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.tools import ToolInvoker\n",
    "from haystack.tools import create_tool_from_function\n",
    "from typing import Annotated\n",
    "\n",
    "def get_current_weather(\n",
    "    location: Annotated[str, \"The city for which to get the weather, e.g. 'San Francisco'\"] = \"Munich\",\n",
    "    unit: Annotated[str, \"The unit for the temperature, e.g. 'celsius'\"] = \"celsius\",\n",
    "):\n",
    "  return {\"weather\": \"sunny\", \"temperature\": 21.8, \"unit\": unit}\n",
    "\n",
    "weather_tool = create_tool_from_function(get_current_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6a43ae-ae3a-47f2-bd57-ff88cb94c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between human language and computers, enabling machines to understand, interpret, and generate human-like text in various applications such as text translation, sentiment analysis, chatbots, and search engines.{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between human language and computers, enabling machines to understand, interpret, and generate human-like text in various applications such as text translation, sentiment analysis, chatbots, and search engines.')], _name=None, _meta={'model': 'hf.co/IlyaGusev/saiga_nemo_12b_gguf:Q8_0', 'index': 0, 'finish_reason': 'stop', 'completion_start_time': '2025-04-18T05:28:28.121267', 'usage': {}})]}\n"
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "client = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    streaming_callback=lambda chunk: print(chunk.content, end=\"\", flush=True)\n",
    ")\n",
    "response = client.run(\n",
    "\t  [ChatMessage.from_user(\"What's Natural Language Processing? Be brief.\")]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4bda71-22b7-4fe4-be00-8867976e1303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin ist die Hauptstadt von Deutschland und eine moderne Metropole mit einer beeindruckenden Geschichte. Die Stadt kombiniert edle Bauwerke, wie das Reichstag oder der Brandenburger Tor, mit modernen Architekturbeispielen in Neukölln oder Prenzlauer Berg. Berlin ist bekannt für seine Vielfalt an Kunst und Kultur: Museen wie das Museum insel auf Museum Island und die DDR-Museum bieten Einblicke in die deutsche Geschichte, während Veranstaltungsorte wie der HAU und der Theater am Avantgarde-Kollektiv für moderne Performance-Aufführungen sorgen. Die Stadt zählt auch zu den führenden Zentren der Kreativität mit zahlreichen Galerien, Künstlerstudios und Designern. Berlin ist eine Stadt für alle Hobbys: von Spaziergängen in der Tiergarten-Schloßanlage bis hin zu Partytouren im Alexanderplatz-Bereich oder den Prenzlauer Berg-Nachtclubs. Darüber hinaus bietet die U-Bahn-Netz der Stadt eine effiziente Möglichkeit, sich an den Orten zu orientieren, wo man sein Interesse amüsant und unterhaltsam erforschen kann."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Berlin ist die Hauptstadt von Deutschland und eine moderne Metropole mit einer beeindruckenden Geschichte. Die Stadt kombiniert edle Bauwerke, wie das Reichstag oder der Brandenburger Tor, mit modernen Architekturbeispielen in Neukölln oder Prenzlauer Berg. Berlin ist bekannt für seine Vielfalt an Kunst und Kultur: Museen wie das Museum insel auf Museum Island und die DDR-Museum bieten Einblicke in die deutsche Geschichte, während Veranstaltungsorte wie der HAU und der Theater am Avantgarde-Kollektiv für moderne Performance-Aufführungen sorgen. Die Stadt zählt auch zu den führenden Zentren der Kreativität mit zahlreichen Galerien, Künstlerstudios und Designern. Berlin ist eine Stadt für alle Hobbys: von Spaziergängen in der Tiergarten-Schloßanlage bis hin zu Partytouren im Alexanderplatz-Bereich oder den Prenzlauer Berg-Nachtclubs. Darüber hinaus bietet die U-Bahn-Netz der Stadt eine effiziente Möglichkeit, sich an den Orten zu orientieren, wo man sein Interesse amüsant und unterhaltsam erforschen kann.')], _name=None, _meta={'model': 'qwen2.5:7b', 'index': 0, 'finish_reason': 'stop', 'completion_start_time': '2025-04-18T06:21:07.396878', 'usage': {}})]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack import Pipeline\n",
    "from haystack.utils import Secret\n",
    "\n",
    "# no parameter init, we don't use any runtime template variables\n",
    "prompt_builder = ChatPromptBuilder()\n",
    "llm = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    streaming_callback=lambda chunk: print(chunk.content, end=\"\", flush=True)\n",
    ")\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipe.add_component(\"llm\", llm)\n",
    "pipe.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "location = \"Berlin\"\n",
    "messages = [ChatMessage.from_system(\"Always respond in German even if some input data is in other languages.\"),\n",
    "            ChatMessage.from_user(\"Tell me about {{location}}\")]\n",
    "pipe.run(data={\"prompt_builder\": {\"template_variables\":{\"location\": location}, \"template\": messages}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418cfaac-1eee-47c4-89c3-1a2333890bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a subfield of artificial intelligence, computer science, and linguistics focused on the interaction between human language and computers. It enables machines to understand, interpret, and generate human language in both spoken and written forms.{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Natural Language Processing (NLP) is a subfield of artificial intelligence, computer science, and linguistics focused on the interaction between human language and computers. It enables machines to understand, interpret, and generate human language in both spoken and written forms.')], _name=None, _meta={'model': 'hf.co/IlyaGusev/saiga_nemo_12b_gguf:Q8_0', 'index': 0, 'finish_reason': 'stop', 'completion_start_time': '2025-04-18T05:35:31.934860', 'usage': {}})]}\n"
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "client = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    streaming_callback=lambda chunk: print(chunk.content, end=\"\", flush=True)\n",
    ")\n",
    "response = client.run(\n",
    "    [ChatMessage.from_user(\"What's Natural Language Processing? Be brief.\")]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bf9a95-db1e-483b-9eed-3cfda54cc4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves programming computers to process, understand, and generate human language in a useful and intelligent way. NLP techniques can be used for tasks such as translation, sentiment analysis, text summarization, and chatbot responses."
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "client = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    streaming_callback=print_streaming_chunk\n",
    ")\n",
    "response = client.run(\n",
    "    [ChatMessage.from_user(\"What's Natural Language Processing? Be brief.\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c889344c-5c1e-402c-84ff-e0969ec5b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\"):\n",
    "  ## Do something\n",
    "  return {\"weather\": \"sunny\", \"temperature\": 21.8, \"unit\": unit}\n",
    "\n",
    "available_functions = {\n",
    "  \"get_current_weather\": get_current_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49387e69-e4c2-4ec0-8d20-0fc27d5d1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"unit\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28345c78-3e18-4f30-9329-4f8b3c50b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "messages = []\n",
    "messages.append(ChatMessage.from_system(\"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"))\n",
    "messages.append(ChatMessage.from_user(\"What's the weather like in Berlin?\"))\n",
    "\n",
    "client = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    streaming_callback=print_streaming_chunk\n",
    ")\n",
    "response = client.run(\n",
    "    messages=messages,\n",
    "    generation_kwargs={\"tools\":tools}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0558f220-739a-4dc1-a578-4572a28db811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[ToolCall(tool_name='get_current_weather', arguments={'location': 'Berlin, Germany', 'unit': 'celsius'}, id='call_6l4u39rc')], _name=None, _meta={'model': 'qwen2.5:7b', 'index': 0, 'finish_reason': 'tool_calls', 'completion_start_time': '2025-04-18T06:21:19.920241', 'usage': {}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2d42029-1a7a-46f5-9c62-c707e372def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response[\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8adaa38-68ab-4ac7-a984-758127bbb8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The `content` attribute of `ChatMessage` has been removed. Use the `text` property to access the textual value. For more information about the new API and how to migrate, see the documentation: https://docs.haystack.deepset.ai/docs/chatmessage",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m function_call = json.loads(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreplies\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m)[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m function_name = function_call[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m function_args = json.loads(function_call[\u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/chatHRD/.venv/lib/python3.12/site-packages/haystack/dataclasses/chat_message.py:174\u001b[39m, in \u001b[36mChatMessage.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    168\u001b[39m     msg = (\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `content` attribute of `ChatMessage` has been removed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse the `text` property to access the textual value. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFor more information about the new API and how to migrate, see the documentation: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.haystack.deepset.ai/docs/chatmessage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    173\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[31mAttributeError\u001b[39m: The `content` attribute of `ChatMessage` has been removed. Use the `text` property to access the textual value. For more information about the new API and how to migrate, see the documentation: https://docs.haystack.deepset.ai/docs/chatmessage"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "function_call = json.loads(response[\"replies\"][0].content)[0]\n",
    "function_name = function_call[\"function\"][\"name\"]\n",
    "function_args = json.loads(function_call[\"function\"][\"arguments\"])\n",
    "print(\"function_name:\", function_name)\n",
    "print(\"function_args:\", function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592ca9ce-3f4a-4de9-819a-50fcab6587b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.run(\n",
    "    messages=messages,\n",
    "    generation_kwargs={\"tools\":tools}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392c9fec-fef0-418c-a638-345cea196366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[], _name=None, _meta={'model': 'qwen2.5:7b', 'index': 0, 'finish_reason': 'stop', 'completion_start_time': '2025-04-18T06:25:03.722324', 'usage': {}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b80f87-02d7-4e61-b5ae-7b697e3ceab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3100c8f9-bd7a-4439-8496-0c52106fac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7a7460725a60>\n",
       "🚅 Components\n",
       "  - retriever: ChromaQueryTextRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "🛤️ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Ответьте на запрос на основе предоставленного контекста.\n",
    "Если контекст не содержит ответа, скажите «Ответ не найден».\n",
    "Контекст:\n",
    "{% for doc in documents %}\n",
    "  {{ doc.content }}\n",
    "{% endfor %}\n",
    "Запрос: {{query}}\n",
    "Ответ:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt)\n",
    "\n",
    "retriever = ChromaQueryTextRetriever(document_store)\n",
    "\n",
    "querying = Pipeline()\n",
    "querying.add_component(\"retriever\", retriever)\n",
    "querying.add_component(\"prompt_builder\", prompt_builder)\n",
    "querying.add_component(\"llm\", llm)\n",
    "\n",
    "querying.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "querying.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855a34b3-651d-41d6-8230-69fd5e539e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Как менялось предназначение здания музея Прадо на протяжении истории, и какие ключевые события повлияли на его становление?\"\n",
    "results = querying.run({\n",
    "    \"retriever\": {\"query\": query, \"top_k\": 3},\n",
    "    \"prompt_builder\": {\"query\": query},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38468244-608f-4723-be38-ac8bf2d45620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Здание музея Прадо прошло значительные изменения своего предназначения за более чем пятивековую историю. Вот основные этапы его развития: 1503 год - основание королевских коллекций, предшествовавших музею (королевская библиотека и художественные коллекции).\n",
      "\n",
      "Ключевые события и факторы влияния на становление музея Прадо:\n",
      "- Консолидация художественных коллекций испанскими монархами в XVI-XVII веках\n",
      "- Строительство Паласио дель Буэнос Айрес (1738) как резиденции Испанской королевской семьи, где размещены основные музейные собрания\n",
      "- Оформление статуса музея королевских коллекций после смерти короля Карла III (1792)\n",
      "- Реорганизация и расширение коллекции во время правления Филиппа V и последующих монархов\n",
      "- Признание Прадо важным культурным центром Европы в XIX веке\n",
      "- Официальное открытие музея в 1819 году как современного учреждения, собирающего произведения искусства\n",
      "\n",
      "На протяжении этих этапов происходило постепенное формирование музея Прадо как одного из ведущих мировых учреждений в области изобразительного искусства. Изменения предназначения здания отражают эволюцию музейной практики и понимания роли музеев в обществе.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fee322-2236-4523-be86-3d9d1bf272e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4fe2630-066c-4ee2-8839-f90efda180c1",
   "metadata": {},
   "source": [
    "Изначально на месте Прадо в XV веке находился охотничий домик короля Энрике III, построенный в 1405 году. Позже, в 1543 году, Карл V Габсбургский начал возводить здесь дворец для своего сына Филиппа II. При Филиппе II во дворце разместилась художественная галерея, но в 1604 году она сгорела и была восстановлена по приказу Филиппа III.\n",
    "\n",
    "В эпоху Просвещения (XVIII век) Карл III Бурбонский превратил парк Прадо в научный центр, разбив ботанический сад и построив здание для Академии наук. Однако это здание так и не стало академией — вместо него в 1819 году открылся музей Прадо по указу Фердинанда VII. Таким образом, от охотничьего домика до королевского дворца, а затем — до всемирно известного музея, Прадо прошёл долгий путь, отражающий изменения в испанской культуре и истории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f86e8c27-21e6-44d4-8309-841ceb48d42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': ['\\nЗдание музея Прадо прошло значительные изменения своего предназначения за более чем пятивековую историю. Вот основные этапы его развития: 1503 год - основание королевских коллекций, предшествовавших музею (королевская библиотека и художественные коллекции).\\n\\nКлючевые события и факторы влияния на становление музея Прадо:\\n- Консолидация художественных коллекций испанскими монархами в XVI-XVII веках\\n- Строительство Паласио дель Буэнос Айрес (1738) как резиденции Испанской королевской семьи, где размещены основные музейные собрания\\n- Оформление статуса музея королевских коллекций после смерти короля Карла III (1792)\\n- Реорганизация и расширение коллекции во время правления Филиппа V и последующих монархов\\n- Признание Прадо важным культурным центром Европы в XIX веке\\n- Официальное открытие музея в 1819 году как современного учреждения, собирающего произведения искусства\\n\\nНа протяжении этих этапов происходило постепенное формирование музея Прадо как одного из ведущих мировых учреждений в области изобразительного искусства. Изменения предназначения здания отражают эволюцию музейной практики и понимания роли музеев в обществе.'],\n",
       "  'meta': [{'model': 'hf.co/IlyaGusev/saiga_yandexgpt_8b_gguf:Q6_K',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 229,\n",
       "     'prompt_tokens': 2048,\n",
       "     'total_tokens': 2277,\n",
       "     'completion_tokens_details': None,\n",
       "     'prompt_tokens_details': None}}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333f7076-0f7b-457b-a9c7-590d798d28db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'replies'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'\\nЗдание музея Прадо прошло значительные изменения своего предназначения за более чем пятивековую </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">историю. Вот основные этапы его развития: 1503 год - основание королевских коллекций, предшествовавших музею </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(королевская библиотека и художественные коллекции).\\n\\nКлючевые события и факторы влияния на становление музея </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Прадо:\\n- Консолидация художественных коллекций испанскими монархами в XVI-XVII веках\\n- Строительство Паласио дель</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Буэнос Айрес (1738) как резиденции Испанской королевской семьи, где размещены основные музейные собрания\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Оформление статуса музея королевских коллекций после смерти короля Карла III (1792)\\n- Реорганизация и расширение </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">коллекции во время правления Филиппа V и последующих монархов\\n- Признание Прадо важным культурным центром Европы в</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">XIX веке\\n- Официальное открытие музея в 1819 году как современного учреждения, собирающего произведения </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">искусства\\n\\nНа протяжении этих этапов происходило постепенное формирование музея Прадо как одного из ведущих </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">мировых учреждений в области изобразительного искусства. Изменения предназначения здания отражают эволюцию музейной</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">практики и понимания роли музеев в обществе.'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'hf.co/IlyaGusev/saiga_yandexgpt_8b_gguf:Q6_K'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2277</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'replies'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'\\nЗдание музея Прадо прошло значительные изменения своего предназначения за более чем пятивековую \u001b[0m\n",
       "\u001b[32mисторию. Вот основные этапы его развития: 1503 год - основание королевских коллекций, предшествовавших музею \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mкоролевская библиотека и художественные коллекции\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nКлючевые события и факторы влияния на становление музея \u001b[0m\n",
       "\u001b[32mПрадо:\\n- Консолидация художественных коллекций испанскими монархами в XVI-XVII веках\\n- Строительство Паласио дель\u001b[0m\n",
       "\u001b[32mБуэнос Айрес \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1738\u001b[0m\u001b[32m)\u001b[0m\u001b[32m как резиденции Испанской королевской семьи, где размещены основные музейные собрания\\n- \u001b[0m\n",
       "\u001b[32mОформление статуса музея королевских коллекций после смерти короля Карла III \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1792\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n- Реорганизация и расширение \u001b[0m\n",
       "\u001b[32mколлекции во время правления Филиппа V и последующих монархов\\n- Признание Прадо важным культурным центром Европы в\u001b[0m\n",
       "\u001b[32mXIX веке\\n- Официальное открытие музея в 1819 году как современного учреждения, собирающего произведения \u001b[0m\n",
       "\u001b[32mискусства\\n\\nНа протяжении этих этапов происходило постепенное формирование музея Прадо как одного из ведущих \u001b[0m\n",
       "\u001b[32mмировых учреждений в области изобразительного искусства. Изменения предназначения здания отражают эволюцию музейной\u001b[0m\n",
       "\u001b[32mпрактики и понимания роли музеев в обществе.'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'meta'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[32m'hf.co/IlyaGusev/saiga_yandexgpt_8b_gguf:Q6_K'\u001b[0m,\n",
       "                \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "                \u001b[32m'usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m229\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m2048\u001b[0m,\n",
       "                    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m2277\u001b[0m,\n",
       "                    \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                    \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rich\n",
    "rich.print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76605fa7-b0ff-4d7d-86ce-7d82c8da101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"Какие особенности картины Питера Брейгеля Старшего «Жатва» отражают его уникальный стиль и влияние эпохи Возрождения?\"\n",
    "results = querying.run({\n",
    "    \"retriever\": {\"query\": query, \"top_k\": 3},\n",
    "    \"prompt_builder\": {\"query\": query},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfcc5f-a6dd-406f-8d5f-7247199d53b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80272373-0198-43fb-b542-1c18de6237d6",
   "metadata": {},
   "source": [
    "Картина «Жатва» сочетает в себе средневековую традицию изображения сезонных работ с ренессансными новациями. Брейгель, вдохновленный итальянской живописью, переработал её элементы, создав монументальный пейзаж с панорамным охватом крестьянской жизни. Его уникальность проявляется в детализированном изображении сельского труда и отдыха, а также в гармоничном равновесии природы и человека. В отличие от современников, Брейгель уделял особое внимание крестьянской теме, передавая её с симпатией и восхищением, что отражает его гуманистический взгляд и прозвище «Мужицкий». Кроме того, картина подчеркивает философскую идею договора между человеком и природой (Богом), характерную для мировоззрения художника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53843657-1881-416c-be80-97cce8d907db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7fddf-664f-4c57-b55c-5f19f4ba7d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9682bd1-f4d1-4811-bc75-76c97c978ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396efe78-ad04-46aa-b054-8273071e7e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b14ce-babd-4006-818d-e7336ed589ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e6e0e-5bb6-4ac5-b292-9b1a501c4ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3483ecb-b644-488a-85ba-51444b3db734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da7724-f9f6-4a65-a752-a18d378af3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426f587-6f32-4195-a0ca-6398e80ff4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e73f2-42ef-483d-a113-ffe5f4231387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1c5c3-7ed6-41d2-bf9b-00a2774b8603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
