{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badd3283-0847-414e-ad32-6e2399fbae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from haystack import Pipeline, component\n",
    "from haystack.dataclasses import Document, ChatMessage\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack_integrations.components.retrievers.chroma import ChromaQueryTextRetriever\n",
    "from rank_bm25 import BM25L\n",
    "import pickle\n",
    "import fitz        # PyMuPDF для быстрого текстового извлечения\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56889b09-0f66-4c30-9502-1e3004af2d85",
   "metadata": {},
   "source": [
    "# Компоненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f5cf3-9afc-4c2d-8d71-7716b5318a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.1.  Классификатор: определяет, нужен ли поиск (search) или можно сразу answer\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@component\n",
    "class QueryClassifier:\n",
    "    @component.output_types(need_search=bool)\n",
    "    def run(self, query: str) -> dict:\n",
    "        # Простая эвристика: если в тексте есть вопросительный знак → поиск\n",
    "        need_search = \"?\" in query.strip()\n",
    "        return {\"need_search\": need_search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fc9a3-a668-4349-a2c0-44476f932257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.2.  Декомпозитор: разбивает сложный запрос на подзапросы (если нужно)\n",
    "#          В этом примере – если в запросе \" и \" или ',' → разбиваем по этим разделителям,\n",
    "#          иначе возвращаем оригинал.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@component\n",
    "class QueryDecomposer:\n",
    "    @component.output_types(subqueries=List[str])\n",
    "    def run(self, query: str) -> dict:\n",
    "        # очень простая декомпозиция\n",
    "        if \" и \" in query or \",\" in query:\n",
    "            parts = [part.strip() for part in query.replace(\",\", \" и \").split(\" и \") if part.strip()]\n",
    "            return {\"subqueries\": parts}\n",
    "        else:\n",
    "            return {\"subqueries\": [query]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751825e9-40b7-4d55-a21c-c1e1e1942769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.3.  Retriever‑компонент на основе BM25 через pickle\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@component\n",
    "class PickledBM25Retriever:\n",
    "    @component.output_types(documents=List[Document])\n",
    "    def __init__(self, path_to_pickle: str = \"../data/bm25.pkl\", top_k: int = 5):\n",
    "        # Загружаем корпус и BM25\n",
    "        with open(path_to_pickle, \"rb\") as f:\n",
    "            self.bm25, self.doc_ids = pickle.load(f)\n",
    "        # Предполагаем, что список doc_ids соотнесён по индексу с первым пайплайном\n",
    "        # и что ChromaDocumentStore хранит документы с теми же id.\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        # токенизируем\n",
    "        tokens = word_tokenize(query.lower())\n",
    "        scores = self.bm25.get_scores(tokens)\n",
    "        # берём top_k\n",
    "        top_n = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[: self.top_k]\n",
    "        # создаём Document-объекты с id и пустым content (контент подтянет Chroma)\n",
    "        docs = [Document(id=self.doc_ids[i], content=\"\", meta={}) for i in top_n]\n",
    "        return {\"documents\": docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead024ab-5d5b-4894-a728-5441f3b2e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.4.  Гибридный Search: BM25 + ChromaQueryTextRetriever → объединяем\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "@component\n",
    "class HybridRetriever:\n",
    "    @component.output_types(documents=List[Document])\n",
    "    def __init__(self, bm25_retriever: PickledBM25Retriever, chroma_retriever: ChromaQueryTextRetriever):\n",
    "        self.bm25 = bm25_retriever\n",
    "        self.chroma = chroma_retriever\n",
    "\n",
    "    def run(self, query: str) -> dict:\n",
    "        docs_bm = self.bm25.run(query)[\"documents\"]\n",
    "        docs_ch = self.chroma.run(query=query)[\"documents\"]\n",
    "        # объединяем, сохраняем уникальность\n",
    "        combined = {d.id: d for d in docs_bm + docs_ch}\n",
    "        return {\"documents\": list(combined.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ba946-b451-4085-bdb8-bae593a86165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.5.  PromptBuilder: формирует единую строку prompt\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "prompt_template = \"\"\"\n",
    "Ты — умный помощник. Отвечай по-русски, используй фрагменты из контекста.\n",
    "Вопрос: {{ query }}\n",
    "\n",
    "Контекст:\n",
    "{% for doc in documents %}\n",
    "--- {{doc.meta.name or doc.id}} ---\n",
    "{{ doc.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Ответ:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(\n",
    "    template=prompt_template,\n",
    "    required_variables=[\"query\", \"documents\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e13adb-c103-4ffe-82e7-16a63a7a7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.6.  Инициализация LLM-генератора (Saiga 12B через Ollama API)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "MODEL_NAME = \"hf.co/IlyaGusev/saiga_nemo_12b_gguf:Q8_0\"\n",
    "llm_gen = OpenAIChatGenerator(\n",
    "    model=MODEL_NAME,\n",
    "    api_key=Secret.from_token(\"ollama\"),\n",
    "    api_base_url=\"http://localhost:11434/v1\",\n",
    "    generation_kwargs={\"temperature\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896c58f-4edb-41e7-b3c8-7cef4863d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.7.  Собираем Pipeline 2\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# 1) входной узел — принимает {'query': str}\n",
    "# 2) classifier → определяет, нужен поиск или нет\n",
    "pipeline.add_component(\"classifier\", QueryClassifier())\n",
    "pipeline.add_component(\"router\", component(_fast_path=None))  # placeholder\n",
    "\n",
    "# Вместо ConditionalRouter — простой Python‑роутер\n",
    "@component\n",
    "class QueryRouter:\n",
    "    @component.output_types(search=str, direct=str)\n",
    "    def run(self, query: str, need_search: bool) -> dict:\n",
    "        if need_search:\n",
    "            return {\"search\": query, \"direct\": \"\"}\n",
    "        else:\n",
    "            return {\"search\": \"\",   \"direct\": query}\n",
    "\n",
    "pipeline.add_component(\"query_router\", QueryRouter())\n",
    "\n",
    "# 3) декомпозиция сложных запросов\n",
    "pipeline.add_component(\"decomposer\", QueryDecomposer())\n",
    "\n",
    "# 4) ретриверы\n",
    "bm25_r = PickledBM25Retriever(path_to_pickle=\"../data/bm25.pkl\", top_k=5)\n",
    "chroma_r = ChromaQueryTextRetriever(\n",
    "    collection_name=\"documents\",\n",
    "    persist_directory=\"data/chroma_index\",\n",
    "    embedding_model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    top_k=5\n",
    ")\n",
    "pipeline.add_component(\"hybrid_retriever\", HybridRetriever(bm25_r, chroma_r))\n",
    "\n",
    "# 5) prompt builder & генератор\n",
    "pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipeline.add_component(\"generator\", llm_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b354e-0ba0-4e67-883e-efc1c9784de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.8.  Подключения\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#  вход: {'query': ...}\n",
    "pipeline.connect(\"query\", \"classifier.query\")\n",
    "pipeline.connect(\"query\", \"query_router.query\")\n",
    "pipeline.connect(\"classifier.need_search\", \"query_router.need_search\")\n",
    "\n",
    "# путь «прямой ответ» (direct) → пропускаем поиск → сразу Prompt+LLM\n",
    "pipeline.connect(\"query_router.direct\", \"prompt_builder.query\")\n",
    "pipeline.connect(\"query_router.direct\", \"prompt_builder.documents\")  # пустой список\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"generator.messages\", sender_role=\"user\")\n",
    "\n",
    "# путь «с поиском» (search) → декомпозиция → hybrid_retriever → Prompt+LLM\n",
    "# note: если пустой search, HybridRetriever просто не найдёт документов\n",
    "pipeline.connect(\"query_router.search\",    \"decomposer.query\")\n",
    "pipeline.connect(\"decomposer.subqueries\", \"hybrid_retriever.query\")\n",
    "pipeline.connect(\"hybrid_retriever.documents\", \"prompt_builder.documents\")\n",
    "pipeline.connect(\"query_router.search\",    \"prompt_builder.query\")\n",
    "\n",
    "# генерация чат‑сообщения\n",
    "# Преобразуем prompt (строку) в ChatMessage\n",
    "@component\n",
    "class ToChatMessage:\n",
    "    @component.output_types(messages=List[ChatMessage])\n",
    "    def run(self, prompt: str) -> dict:\n",
    "        return {\"messages\": [ChatMessage(role=\"user\", content=prompt)]}\n",
    "\n",
    "pipeline.add_component(\"to_chat\", ToChatMessage())\n",
    "pipeline.connect(\"prompt_builder.prompt\", \"to_chat.prompt\")\n",
    "pipeline.connect(\"to_chat.messages\",       \"generator.messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe0f4e-48d2-4b36-8ec7-5ca41d87729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Запуск и проверка\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример 1: простой direct‑запрос\n",
    "    out = pipeline.run({\"query\": \"Привет, как дела?\"})\n",
    "    print(\"Direct:\", out[\"generator.replies\"])\n",
    "\n",
    "    # Пример 2: информационный запрос\n",
    "    out = pipeline.run({\"query\": \"Какие новые политики отпуска и сколько дней теперь положено?\"})\n",
    "    print(\"Answer:\", out[\"generator.replies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d06f89-a836-4dc0-9fe8-05274c4e3329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e15bc-cc6c-45bd-bcbc-010fa9b6f07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bb284-690c-4304-9831-e7881b931233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8741c43-f48b-46b8-9709-0a3d0704bf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4798e94-f9b9-4ede-a965-b18484768267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643302f-5ba9-4158-9fa9-167cde772de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdebaea-2f5d-4162-9b65-f70f6eff34f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76745e-0b49-4fc7-b1e6-e54988e50c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf71281-fbfc-46b0-82ca-2c44b6f0bbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71db27-5abb-4ee1-bb98-98f3bec02716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69681629-92db-4cbe-811d-4d2e651037ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714de233-ed2f-4756-bea4-dd789d40e1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e0816-2a06-4d16-8806-377727043b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfefbec-077c-4ed0-ae71-280cb871036c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93436406-d531-4bc8-846e-0b479fb77fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3438b2-e223-48a7-a673-d3edf3fb2fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c3567-cb20-4c82-91ac-af2a486e628c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd78ac3-d498-477d-8f19-06ee7486cf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc9a20-fb3f-4d59-93e5-1516b82f5635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fb6d0-5b88-4411-bef0-8f9ecc4cb21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498bc03-f3bc-4c93-88e1-4be4db28cc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1896b-d952-4e3a-ba54-b6d0a7972cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c00c09-0cce-4a98-977f-b7b3a38ebcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966c356-415b-4b44-b8c4-4e7e28369c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4ea3a-23ac-4946-908b-2764a6406731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150ff49-918d-4e34-b583-88e453e7b2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121fbbd-982d-4579-b863-fd76107cd263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d54a0-32c0-41b8-b4cb-a68a74930c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ae7c3-6973-4708-889d-0c2787cdcd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc0893-0445-4d30-9653-39cdf502b282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d951d-6e4f-43cc-99c2-4b7ebdbea462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c48e2-cc7d-4f5d-a653-daa2aee3e71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
